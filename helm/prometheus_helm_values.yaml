# Prometheus Stack Helm Values - Unified Configuration
# Backend-only stack: Prometheus + Node Exporter + Kube State Metrics + AlertManager
# Grafana disabled (using unified Grafana instance with Loki)

## Global Configuration
fullnameOverride: "prometheus-stack"

## Prometheus Configuration
prometheus:
  prometheusSpec:
    # Storage configuration
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: managed-csi
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    
    # Retention policy
    retention: "15d"
    retentionSize: "45GB"
    
    # Resource limits - monitoring node has 4 vCPUs, 16GB RAM
    resources:
      limits:
        cpu: 2000m
        memory: 4Gi
      requests:
        cpu: 1000m
        memory: 2Gi
    
    # Node selector for monitoring nodes
    nodeSelector:
      agentpool: monitoring
    
    # Tolerations for monitoring nodes
    tolerations:
      - key: "monitoring"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
    
    # Service configuration - ClusterIP only (accessed via unified Grafana)
    service:
      type: ClusterIP
      port: 9090
    
    # Additional scrape configs for custom node pool monitoring
    additionalScrapeConfigs:
      - job_name: 'kubernetes-nodes-spot'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__meta_kubernetes_node_label_agentpool]
            action: keep
            regex: spot
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
      
      - job_name: 'kubernetes-nodes-regular'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__meta_kubernetes_node_label_agentpool]
            action: keep
            regex: regular
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
      
      - job_name: 'kubernetes-nodes-monitoring'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__meta_kubernetes_node_label_agentpool]
            action: keep
            regex: monitoring
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics

## Grafana Configuration - DISABLED (using unified Loki+Prometheus Grafana)
grafana:
  enabled: false

## AlertManager Configuration
alertmanager:
  alertmanagerSpec:
    # Storage
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: managed-csi
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi
    
    # Resources - optimized for monitoring node
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 250m
        memory: 512Mi
    
    # Node selector for monitoring nodes
    nodeSelector:
      agentpool: monitoring
    
    # Tolerations for monitoring nodes
    tolerations:
      - key: "monitoring"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
    
    # Service configuration - ClusterIP only (accessed via Grafana)
    service:
      type: ClusterIP
      port: 9093

## Node Exporter Configuration
nodeExporter:
  # Enable on all nodes (spot, regular, monitoring, and system)
  enabled: true
  
  # Run on all nodes including master
  hostRootFsMount:
    enabled: true
    mountPropagation: HostToContainer
  
  # Tolerations to run on all nodes
  tolerations:
    - operator: "Exists"
      effect: "NoSchedule"
    - operator: "Exists"
      effect: "NoExecute"

## Kube State Metrics Configuration
kubeStateMetrics:
  enabled: true
  
  # Node selector for monitoring nodes
  nodeSelector:
    agentpool: monitoring
  
  # Tolerations for monitoring nodes
  tolerations:
    - key: "monitoring"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"

## Prometheus Operator Configuration
prometheusOperator:
  # Node selector for monitoring nodes
  nodeSelector:
    agentpool: monitoring
  
  # Tolerations for monitoring nodes
  tolerations:
    - key: "monitoring"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"
  
  # Resources
  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 250m
      memory: 512Mi

## Additional monitoring components
kubeApiServer:
  enabled: true

kubelet:
  enabled: true

kubeControllerManager:
  enabled: true

coreDns:
  enabled: true

kubeEtcd:
  enabled: true

kubeScheduler:
  enabled: true

kubeProxy:
  enabled: true
