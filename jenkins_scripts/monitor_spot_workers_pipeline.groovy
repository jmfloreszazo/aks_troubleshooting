// monitor_spot_workers_pipeline.groovy
// Simple monitoring pipeline that runs every 5 minutes
// Keeps spot workers active and shows execution times

import jenkins.model.*
import org.jenkinsci.plugins.workflow.job.WorkflowJob
import org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition

def jenkins = Jenkins.getInstance()

// Create monitoring pipeline job
def jobName = "Spot-Workers-Monitor"
def existingJob = jenkins.getItem(jobName)
if (existingJob != null) {
    existingJob.delete()
}

def job = jenkins.createProject(WorkflowJob.class, jobName)

def pipelineScript = '''
pipeline {
    agent { label 'nodepool=spot' }
    
    options {
        timeout(time: 2, unit: 'MINUTES')
        buildDiscarder(logRotator(numToKeepStr: '50'))
    }
    
    triggers {
        cron('*/5 * * * *')  // Every 5 minutes
    }
    
    environment {
        MONITOR_VERSION = "1.0"
    }
    
    stages {
        stage('Spot Worker Health Check') {
            steps {
                script {
                    def startTime = new Date()
                    def buildNum = env.BUILD_NUMBER ?: "Unknown"
                    def nodeName = env.NODE_NAME ?: "Unknown"
                    def workspace = env.WORKSPACE ?: "Unknown"
                    
                    echo "============================================"
                    echo "SPOT WORKERS HEALTH MONITORING - BUILD #${buildNum}"
                    echo "============================================"
                    echo ""
                    echo "üîç DIAGNOSTIC INFORMATION:"
                    echo "  Start Time: ${startTime.format('yyyy-MM-dd HH:mm:ss')}"
                    echo "  Node Name: ${nodeName}"
                    echo "  Build Number: ${buildNum}"
                    echo "  Workspace: ${workspace}"
                    echo "  Monitor Version: ${env.MONITOR_VERSION}"
                    echo ""
                    
                    // Detailed Pod/Node Analysis for troubleshooting
                    echo "üè∑Ô∏è  POD/NODE DIAGNOSTIC:"
                    sh """
                        echo "  Hostname: \\$(hostname)"
                        echo "  Pod Name: \\$(hostname)"
                        echo "  Node IP: \\$(hostname -i 2>/dev/null || echo 'IP not available - possible network issue')"
                        
                        # Check pod uptime and status
                        UPTIME_SECONDS=\\$(cat /proc/uptime | cut -d. -f1)
                        UPTIME_MINUTES=\\$((UPTIME_SECONDS / 60))
                        UPTIME_HOURS=\\$((UPTIME_MINUTES / 60))
                        
                        if [ "\\$UPTIME_SECONDS" -lt 60 ]; then
                            echo "  üÜï Pod Status: FRESHLY CREATED (\\${UPTIME_SECONDS}s ago)"
                            echo "  ‚ö†Ô∏è  WARNING: Very new pod - possible recent restart/eviction"
                        elif [ "\\$UPTIME_SECONDS" -lt 300 ]; then
                            echo "  ‚ú® Pod Status: RECENTLY CREATED (\\${UPTIME_MINUTES}m ago)"
                            echo "  ‚ÑπÔ∏è  INFO: Pod started recently - monitor for stability"
                        elif [ "\\$UPTIME_SECONDS" -lt 3600 ]; then
                            echo "  ‚ôªÔ∏è  Pod Status: STABLE REUSE (\\${UPTIME_MINUTES}m uptime)"
                            echo "  ‚úÖ GOOD: Pod is stable and reusable"
                        else
                            echo "  üîÑ Pod Status: LONG RUNNING (\\${UPTIME_HOURS}h uptime)"
                            echo "  ‚úÖ EXCELLENT: Very stable pod"
                        fi
                        
                        echo "  üìä Uptime Details: \\$(uptime)"
                    """
                    
                    echo ""
                    echo "üîß SYSTEM HEALTH DIAGNOSTIC:"
                    sh """
                        # Memory pressure check
                        MEMORY_USED=\\$(free | grep Mem | awk '{printf "%.0f", \\$3/\\$2 * 100}')
                        echo "  üíæ Memory Usage: \\${MEMORY_USED}%"
                        if [ "\\$MEMORY_USED" -gt 90 ]; then
                            echo "  üö® CRITICAL: High memory usage - possible OOM kill risk"
                        elif [ "\\$MEMORY_USED" -gt 70 ]; then
                            echo "  ‚ö†Ô∏è  WARNING: Elevated memory usage"
                        else
                            echo "  ‚úÖ GOOD: Memory usage normal"
                        fi
                        
                        # Disk pressure check
                        DISK_USED=\\$(df / | tail -1 | awk '{print \\$5}' | sed 's/%//')
                        echo "  üíΩ Disk Usage: \\${DISK_USED}%"
                        if [ "\\$DISK_USED" -gt 90 ]; then
                            echo "  üö® CRITICAL: Disk almost full - pod eviction risk"
                        elif [ "\\$DISK_USED" -gt 80 ]; then
                            echo "  ‚ö†Ô∏è  WARNING: High disk usage"
                        else
                            echo "  ‚úÖ GOOD: Disk usage normal"
                        fi
                        
                        # Load average check
                        LOAD=\\$(uptime | awk -F'load average:' '{print \\$2}' | awk '{print \\$1}' | sed 's/,//')
                        echo "  ‚ö° Load Average: \\$LOAD"
                        
                        # CPU count for context
                        CPU_COUNT=\\$(nproc)
                        echo "  üñ•Ô∏è  CPU Cores: \\$CPU_COUNT"
                        
                        # Check if load is high relative to CPU count
                        if command -v bc >/dev/null 2>&1; then
                            LOAD_RATIO=\\$(echo "\\$LOAD / \\$CPU_COUNT" | bc -l | awk '{printf "%.2f", \\$0}')
                            echo "  üìà Load/CPU Ratio: \\$LOAD_RATIO"
                        fi
                    """
                    
                    echo ""
                    echo "üåê NETWORK CONNECTIVITY TEST:"
                    sh """
                        # Test internal cluster connectivity
                        echo "  üîó Testing cluster DNS..."
                        if nslookup kubernetes.default.svc.cluster.local >/dev/null 2>&1; then
                            echo "  ‚úÖ GOOD: Cluster DNS resolution working"
                        else
                            echo "  üö® CRITICAL: Cluster DNS resolution failed"
                        fi
                        
                        # Test external connectivity
                        echo "  üåç Testing external connectivity..."
                        if ping -c 1 -W 3 8.8.8.8 >/dev/null 2>&1; then
                            echo "  ‚úÖ GOOD: External network connectivity OK"
                        else
                            echo "  ‚ö†Ô∏è  WARNING: External connectivity issues"
                        fi
                        
                        # Test Jenkins master connectivity
                        echo "  üèóÔ∏è  Testing Jenkins master connectivity..."
                        if [ -n "\\$JENKINS_URL" ]; then
                            if curl -s --connect-timeout 5 "\\$JENKINS_URL" >/dev/null 2>&1; then
                                echo "  ‚úÖ GOOD: Jenkins master reachable"
                            else
                                echo "  üö® CRITICAL: Cannot reach Jenkins master"
                            fi
                        else
                            echo "  ‚ÑπÔ∏è  INFO: JENKINS_URL not set, skipping test"
                        fi
                    """
                    
                    echo ""
                    echo "‚ò∏Ô∏è  KUBERNETES ENVIRONMENT CHECK:"
                    sh """
                        if [ -n "\\$KUBERNETES_SERVICE_HOST" ]; then
                            echo "  üéØ Environment: Kubernetes Pod"
                            echo "  üè† Service Host: \\$KUBERNETES_SERVICE_HOST"
                            echo "  üì¶ Namespace: \\${KUBERNETES_NAMESPACE:-default}"
                            echo "  üé´ Service Account: \\$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace 2>/dev/null || echo 'Not available')"
                            
                            # Check for spot instance annotations/labels
                            echo "  üí∞ Checking spot instance indicators..."
                            if [ -f /proc/cpuinfo ]; then
                                echo "  üîç Instance type detection attempted"
                            fi
                            
                            # Check for Azure spot instance metadata if available
                            if command -v curl >/dev/null 2>&1; then
                                SPOT_CHECK=\\$(curl -s -H "Metadata:true" "http://169.254.169.254/metadata/instance/compute/priority?api-version=2021-02-01" 2>/dev/null || echo "unknown")
                                if [ "\\$SPOT_CHECK" = "Spot" ]; then
                                    echo "  üí∏ ‚úÖ CONFIRMED: Running on Azure Spot Instance"
                                elif [ "\\$SPOT_CHECK" = "Regular" ]; then
                                    echo "  üí∞ ‚ÑπÔ∏è  INFO: Running on Regular Instance (not spot)"
                                else
                                    echo "  ü§∑ INFO: Spot status unknown (metadata not available)"
                                fi
                            fi
                        else
                            echo "  üñ•Ô∏è  Environment: Standalone or Docker"
                            echo "  ‚ö†Ô∏è  WARNING: Not running in Kubernetes - unexpected for spot workers"
                        fi
                    """
                    
                    echo ""
                    echo "üîÑ SPOT WORKER STABILITY TEST:"
                    
                    // Test worker responsiveness with small tasks
                    for (int i = 1; i <= 3; i++) {
                        echo "  üìã Running stability test ${i}/3..."
                        sh "echo '    Test ${i}: Basic command execution' && sleep 1"
                        sh "echo '    Test ${i}: File system write test' && echo 'test' > /tmp/spot_test_${i}.txt && rm -f /tmp/spot_test_${i}.txt"
                        echo "    ‚úÖ Test ${i} completed successfully"
                    }
                    
                    def endTime = new Date()
                    def duration = (endTime.time - startTime.time) / 1000
                    
                    echo ""
                    echo "üìä MONITORING SUMMARY:"
                    echo "  ‚è∞ End Time: ${endTime.format('yyyy-MM-dd HH:mm:ss')}"
                    echo "  ‚è±Ô∏è  Total Duration: ${duration} seconds"
                    echo "  üéØ Worker Status: RESPONDING ‚úÖ"
                    echo "  üìÖ Next Check: ${new Date(endTime.time + 300000).format('HH:mm:ss')} (in 5 min)"
                    echo ""
                    echo "üèÅ DIAGNOSTIC RESULT: SPOT WORKER HEALTHY"
                    echo "============================================"
                }
            }
        }
        
        stage('Performance Stress Test') {
            when {
                expression { 
                    // Run stress test every 6th execution (every 30 minutes)
                    return (env.BUILD_NUMBER as Integer) % 6 == 0 
                }
            }
            steps {
                script {
                    echo ""
                    echo "üèãÔ∏è  EXTENDED PERFORMANCE TEST (Every 30 min)"
                    echo "============================================"
                    
                    sh """
                        echo "  üß™ Running CPU stress test..."
                        timeout 10 yes > /dev/null &
                        CPU_PID=\\$!
                        sleep 5
                        kill \\$CPU_PID 2>/dev/null || true
                        echo "  ‚úÖ CPU stress test completed"
                        
                        echo "  üß™ Running memory allocation test..."
                        timeout 5 dd if=/dev/zero of=/tmp/memory_test bs=1M count=50 2>/dev/null || true
                        rm -f /tmp/memory_test 2>/dev/null || true
                        echo "  ‚úÖ Memory test completed"
                        
                        echo "  üß™ Running I/O stress test..."
                        timeout 5 dd if=/dev/zero of=/tmp/io_test bs=1M count=100 2>/dev/null || true
                        rm -f /tmp/io_test 2>/dev/null || true
                        echo "  ‚úÖ I/O test completed"
                    """
                    
                    echo "  üéØ RESULT: Spot worker survived stress test"
                    echo "============================================"
                }
            }
        }
    }
    
    post {
        always {
            script {
                def currentTime = new Date()
                def nodeName = env.NODE_NAME ?: "Unknown"
                echo ""
                echo "üìã MONITORING CYCLE COMPLETED"
                echo "============================================"
                echo "Next spot worker health check in 5 minutes"
                echo "Continuous monitoring active for spot stability"
            }
        }
        success {
            script {
                def currentTime = new Date()
                def nodeName = env.NODE_NAME ?: "Unknown"
                echo ""
                echo "‚úÖ SUCCESS - ${currentTime.format('HH:mm:ss')} - Pod: ${nodeName}"
                echo "üéØ Spot worker is healthy and responsive"
                echo "üí∞ Cost optimization functioning correctly"
            }
        }
        failure {
            script {
                def currentTime = new Date()
                def nodeName = env.NODE_NAME ?: "Unknown"
                echo ""
                echo "‚ùå FAILURE - ${currentTime.format('HH:mm:ss')} - Pod: ${nodeName}"
                echo "üö® SPOT WORKER ISSUE DETECTED"
                echo "============================================"
                echo "TROUBLESHOOTING STEPS:"
                echo "1. Check if spot instances are being evicted by Azure"
                echo "2. Verify nodepool=spot label configuration"
                echo "3. Check resource quotas and limits"
                echo "4. Review pod scheduling tolerations"
                echo "5. Check Azure spot instance availability in region"
                echo "6. Verify RBAC permissions for spot worker creation"
                echo "============================================"
            }
        }
        unstable {
            script {
                def currentTime = new Date()
                def nodeName = env.NODE_NAME ?: "Unknown"
                echo ""
                echo "‚ö†Ô∏è  UNSTABLE - ${currentTime.format('HH:mm:ss')} - Pod: ${nodeName}"
                echo "üîç Spot worker showing signs of instability"
                echo "Monitor next execution for potential issues"
            }
        }
    }
}
'''

job.setDefinition(new CpsFlowDefinition(pipelineScript, true))
job.save()

println "Advanced Spot Worker Monitoring pipeline '${jobName}' created successfully"
println ""
println "üîç DIAGNOSTIC CAPABILITIES:"
println "  ‚úÖ Pod lifecycle detection (new/reused/long-running)"
println "  ‚úÖ Memory pressure monitoring (OOM kill prevention)"
println "  ‚úÖ Disk usage monitoring (eviction prevention)"
println "  ‚úÖ Network connectivity testing (cluster + external)"
println "  ‚úÖ Azure spot instance verification"
println "  ‚úÖ Jenkins master connectivity check"
println "  ‚úÖ Kubernetes environment validation"
println "  ‚úÖ Worker stability testing"
println "  ‚úÖ Performance stress testing (every 30 min)"
println ""
println "üö® TROUBLESHOOTING FEATURES:"
println "  - Detects spot instance evictions"
println "  - Identifies resource pressure issues"
println "  - Monitors pod restart patterns"
println "  - Tests network connectivity problems"
println "  - Validates worker responsiveness"
println "  - Provides actionable error messages"
println ""
println "üìä MONITORING CONFIGURATION:"
println "  Execution Schedule: Every 5 minutes (cron: */5 * * * *)"
println "  Target: Spot workers (nodepool=spot)"
println "  Timeout: 2 minutes per execution"
println "  Build History: Last 50 executions"
println "  Stress Tests: Every 30 minutes"
println ""
println "üéØ CLIENT ISSUE DETECTION:"
println "  This pipeline will help identify:"
println "  - Why spot workers are falling down"
println "  - When spot instances get evicted"
println "  - Resource pressure causing restarts"
println "  - Network connectivity issues"
println "  - Configuration problems"
println ""
println "Usage:"
println "1. The pipeline will start automatically every 5 minutes"
println "2. Check Jenkins dashboard for execution status"
println "3. Review logs to monitor spot worker activity"
println "4. Use 'Build Now' for manual execution if needed"
println ""

jenkins.save()

println "Continuous monitoring configured and active"
